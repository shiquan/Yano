#DScore <- function(x = NULL, y = NULL, W = NULL)
#{
#  d <- .Call("D_score_lite", x, y, W)
#  d
#}

#
#' @importFrom methods is
#
IdentToCells <- function(
  object,
  ident,
  cellnames.use
) {
  #
  if (is.null(x = ident)) {
    stop("Please provide ident")
  } else if ((length(x = ident) == 1 && ident[1] == 'clustertree') || is(object = ident, class2 = 'phylo')) {
    tree <- if (is(object = ident, class2 = 'phylo')) {
      ident
    } else {
      Tool(object = object, slot = 'BuildClusterTree')
    }
    if (is.null(x = tree)) {
      stop("Please run 'BuildClusterTree' or pass an object of class 'phylo' as 'ident'")
    }
    ident <- tree$tip.label[GetLeftDescendants(tree = tree, node = ident)]
  }
  if (length(x = as.vector(x = ident)) > 1 &&
        any(as.character(x = ident) %in% cellnames.use)) {
    bad.cells <- cellnames.use[which(x = !as.character(x = ident) %in% cellnames.use)]
    if (length(x = bad.cells) > 0) {
      stop(paste0("The following cell names provided to ident are not present in the object: ", paste(bad.cells, collapse = ", ")))
    }
  } else {
    ident <- WhichCells(object = object, idents = ident)
  }
  return(ident)
}


#' @name RunBlockCorr
#' @title Run spatial dissimilarity test for features and their binding features in parallel.
#' @param object Seurat object
#' @param bind.name Title name for binding features in the meta table. Consider most users start Yano to perform alternative splicing analysis, the default bind.name set to "gene_name".
#' @param features Vector of features to calculate. Default is AutoCorrFeatures(object).
#' @param assay Work assay.
#' @param min.cells Features detected in few than minimal number of cells will be skipped. Default is 10.
#' @param bind.assay Name of binding assay.
#' @param bind.features List of bind features. Default use all.
#' @param min.cells.bind Binding features detected in few than minimal number of cells will be skipped. Default is 10.
#' @param prefix Prefix name for output scores and values. Default is same with bind.name.
## @param subset Rules for subset meta table before select features to perform test.
#' @param scale.factor Scale factor to normalise counts. Default is 1e4. For mode 1, this function will use data from Layer 'data'. For mode 2 and 3, will use data from Layer 'counts'. The counts will further be normalised with sample size and scale factor for spatial dissimilarity test.
#' @param mode Test mode. For mode 1, X (test feature) vs Y (binding feature). For mode 2, X vs (Y-X). For mode 3, X vs (Y+X). Please note, when set to mode 2 or 3, will use raw counts to update expression value of binding features. Then normalise the counts before testing. For mode 1, will use Layer 'data'. Default is mode 1.
#' @param method Method to use. Support D, D2 and Lee. \eqn{D = sqrt(L_x)(1-r_xy)}. \eqn{D2 = sqrt(L_x)sqrt(L_y)(1-r_xy)}. Lee for Lee's Score. In default use D method, see the manual for details.
#' @param library.size Library size for each cell, used for normalise counts when mode is 2 or 3. If not set, use colSum(counts) instead.
## @param scale Scale expression of the test feature and binding feature when perfroming test.
#' @param weight.matrix.name Weight matrix name, this matrix (graph) generated by \code{\link{RunAutoCorr}}.
#' @param cells Calculate scores for predefined cells. Will reconstruct the SNN graph and weight matrix for these cells with 'reduction' space (usually be pca or harmony). Only weight matrix that calculated by SNN is supported if cells/idents/node is defined.
#' @param idents Calculate scores for these cell groups. The idents should be a vector of group names in Idnets(object).
#' @param node A node to find markers for and all its children; requires \code{\link{BuildClusterTree}} to have been run previously. Only can be used if test all groups.
#' @param reduction Dimension reduction name for constructing SNN graph and weight matrix. Default is 'pca'.
#' @param dims Dimensions of reduction used to construct SNN graph.
#' @param k.param Defines k for the k-nearest neighbor algorithm.
#' @param prune.SNN Sets the cutoff for acceptable Jaccard index when computing the neighborhood overlap for the SNN construction. Any edges with values less than or equal to this will be set to 0 and removed from the SNN graph. Essentially sets the stringency of pruning (0 --- no pruning, 1 --- prune everything). Default is 1/15.
#' @param nn.method Method for nearest neighbor finding. Options include: rann, annoy(default).
#' @param annoy.metric Distance metric for annoy. Options include: euclidean (default), cosine, manhattan, and hamming
#' @param n.trees More trees gives higher precision when using annoy approximate nearest neighbor search. Default is 50.
#' @param nn.eps Error bound when performing nearest neighbor seach using RANN; default of 0.0 implies exact nearest neighbor search
#' @param perm Permutations for evaluating mean and sd of D/L scores. Default is 100.
#' @param seed Seed for generate random number. Default is 999.
#' @param threads Threads. If set to 0 (default), will auto check the CPU cores and set threads = number of CPU cores -1.
#' @param versbose Print log message. Default is TRUE.
#' @param debug Print debug message. Will auto set thread to 1. Default is FALSE.
#' @importFrom Matrix sparseMatrix
#' @export
RunBlockCorr <- function(object = NULL,
                         bind.name = "gene_name",
                         features = NULL,
                         assay = NULL,
                         min.cells = 10,
                         bind.assay = NULL,
                         bind.features = NULL,
                         min.cells.bind = 10,
                         prefix = NULL,
                         # subset = NULL,
                         min.features.per.block = 1,
                         scale.factor = 1e4,
                         mode = c(1,2,3),
                         method = c("D", "D2", "Lee"),
                         library.size = NULL,                         
                         weight.matrix.name = "WeightMatrix",
                         cells = NULL,
                         idents = NULL,
                         node = NULL,
                         reduction = "pca",
                         dims = 1:10,
                         k.param = 20,
                         prune.SNN = 1/15,
                         n.trees = 50,
                         nn.eps = 0,
                         nn.method = "annoy",
                         annoy.metric = "euclidean",
                         perm=100,
                         seed=999,
                         threads = 0,
                         verbose = TRUE,
                         debug = FALSE
                         )
{
  method <- match.arg(method)
  mode <- mode[1L]
  tt <- Sys.time()

  assay <- assay %||% DefaultAssay(object)
  if (isTRUE(verbose)) {
    message("Working on assay ", assay, ".")
  }

  if (!is.null(bind.assay)) {
    if (bind.assay %ni% names(object)) {
      stop("No bind.assay is found. Make sure you specify the correct assay name.")
    } else {
      if (isTRUE(verbose)) {
        message("Working on binding assay ", bind.assay, ".")
      }
    }
  }
  
  features <- features %||% AutoCorrFeatures(object)
  features <- intersect(features, rownames(object))

  if (isTRUE(verbose)) {
    message("Processing ", length(features), " features.")
  }
  threads <- getCores(threads)
  
  object0 <- object[[assay]]
  tab <- object0[[]]

  if (bind.name %ni% colnames(tab)) {
    stop("No bind.name found in the feature table of assay ", assay, ". Run ParseExonName or ParseVarName first.")
  }

  # skip unannotated records
  tab <- tab[tab[[bind.name]] != "." & !is.na(tab[[bind.name]]),] 
  
  ## if (!is.null(subset)) {
  ##   tab <- base::subset(tab, subset = subset)
  ## }
  
  blocks <- names(which(table(tab[[bind.name]]) >= min.features.per.block))

  bind.features <- bind.features %||% blocks
  blocks <- intersect(bind.features, blocks)
  features <- intersect(features, rownames(tab))

  if (length(features) == 0) {
    stop("No features found.")
  }
  
  tab0 <- tab[features,]
  blocks <- intersect(unique(tab0[[bind.name]]), blocks)

  if (isTRUE(verbose)) {
    message("Processing ", length(blocks), " blocks.")
  }
  tab <- subset(tab, tab[[bind.name]] %in% blocks)
  # features <- intersect(features, rownames(tab))

  x <- GetAssayData1(object, assay = assay, layer = "counts")  
  cs <- library.size %||% colSums(x)

  rs <- Matrix::rowSums(x>0)
  idx <- which(rs >= min.cells)
  features1 <- rownames(object)[idx]
  features <- intersect(features, features1)

  bind.assay <- bind.assay %||% "tmp.assay"
  cells0 <- cells %||% colnames(object)
  cells0 <- intersect(cells0, colnames(object))
  
  if (bind.assay %ni% names(object)) {

    if (min.features.per.block == 1) {
      if (isTRUE(verbose)) {
        message("No bind.assay specified, update min.features.per.block to 2.")
      }
      min.features.per.block <- 2
      blocks <- names(which(table(tab[[bind.name]]) >= min.features.per.block))
      tab <- subset(tab, tab[[bind.name]] %in% blocks)
      features <- intersect(features, rownames(tab))
    }

    if (isTRUE(verbose)) {
      message("Aggregate counts.")
    }
    x0 <- x[rownames(tab), cells0]
    x0 <- as(x0, "TsparseMatrix")
    
    # Aggregate features in the same block
    y <- sparseMatrix(i = match(tab[[bind.name]][x0@i+1], blocks),
                      j = x0@j+1,
                      x = x0@x, dims=c(length(blocks), length(cells0)))

    rm(x0)
    rownames(y) <- blocks
    colnames(y) <- colnames(x)
  } else {
    blocks <- unique(tab[[bind.name]])
    if (isTRUE(verbose)) {
      message("Retrieve binding data from assay ", bind.assay, ".")
    }
    old.assay <- DefaultAssay(object)
    DefaultAssay(object) <- bind.assay
    blocks <- intersect(blocks, rownames(object))

    y <- GetAssayData1(object, assay = bind.assay, slot = "counts")

    rs <- Matrix::rowSums(y>0)
    idx <- which(rs >= min.cells.bind)
    blocks1 <- rownames(object)[idx]
    blocks <- intersect(blocks, blocks1)

    tab <- subset(tab, tab[[bind.name]] %in% blocks)
    
    DefaultAssay(object) <- old.assay
  }

  features <- intersect(features, rownames(tab))
  tab <- tab[features,]
  bidx <- match(tab[[bind.name]],rownames(y))
  idx <- match(features, rownames(x))
  if (isTRUE(verbose)) {
    message("Using ", threads, " threads.")
  }
  gc()

  if (isTRUE(verbose)) {
    message("Using method \"", method, "\" with mode ", mode, ".")
  }
  method <- switch(method, "D" = 1, "D2" = 2, "L" == 3)
  scale <- FALSE
  tab <- object0[[]]
  
  if (length(idents) > 0 || !is.null(node)) {
    if (verbose) {
      message("Construct SNN graph for cells with \"", reduction, "\"", ".")
    }
    if (!is.null(node)) {
      ## this part copied from Seurat::FindAllMarkers, credited to origial authoers
      if (!PackageCheck('ape', error = FALSE)) {
        stop("Cluster tree functionality requires 'ape', please install with 'install.packages('ape')'")
      }
      tree <- Tool(object = object, slot = 'BuildClusterTree')
      if (is.null(x = tree)) {
        stop("Please run 'BuildClusterTree' before finding markers on nodes")
      }
      descendants <- DFT(tree = tree, node = node, include.children = TRUE)
      all.children <- sort(x = tree$edge[, 2][!tree$edge[, 2] %in% tree$edge[, 1]])
      descendants <- MapVals(
        vec = descendants,
        from = all.children,
        to = tree$tip.label
      )
      drop.children <- setdiff(x = tree$tip.label, y = descendants)
      keep.children <- setdiff(x = tree$tip.label, y = drop.children)
      orig.nodes <- c(
        node,
        as.numeric(x = setdiff(x = descendants, y = keep.children))
      )
      tree <- ape::drop.tip(phy = tree, tip = drop.children)
      new.nodes <- unique(x = tree$edge[, 1, drop = TRUE])
      idents <- (tree$Nnode + 2):max(tree$edge)
    }

    #cellnames.use <- colnames(x = object0)
    cellnames.use <- cells0

    messages <- list()    
    for (i in 1:length(idents)) {
      if (verbose) {
        message("Calculating cluster ", idents[i], ".")
      }

      cells <- IdentToCells(object = object, ident = idents[[i]], cellnames.use = cellnames.use)
      data.use <- Embeddings(object[[reduction]])
      data.use <- data.use[cells, dims]
      ng <- FindNeighbors(object = data.use,
                          k.param = k.param,
                          compute.SNN = TRUE,
                          prune.SNN = prune.SNN,
                          nn.method = nn.method,
                          annoy.metric = annoy.metric,
                          n.trees = n.trees,
                          nn.eps = nn.eps,
                          l2.norm = FALSE, cache.index = FALSE, verbose = FALSE)
      snn <- ng[['snn']]
      W <- GetWeights(snn = snn, prune.SNN = prune.SNN)
      
      ta <- tryCatch(
        expr = {
          .Call("D_test", x[,cells], y[,cells], W[cells,cells], method, perm, threads, idx, bidx, cs[cells], scale.factor, mode, scale, TRUE, seed, debug)
        },
        error = function(cond){
          return(cond$message)
        }
      )
      
      if (length(ta) == 1) {
        message[[i]] <- ta
      } else {    
        r <- ta[[1]]
        e <- ta[[2]]
        tval <- ta[[3]]
        mval <- ta[[4]]
        vval <- ta[[5]]
        
        names(r) <- features
        names(e) <- features
        names(mval) <- features
        names(vval) <- features
        
        pval <- pt(tval, df = perm - 1, lower.tail = FALSE)
        names(pval) <- features
        if (length(idents) == 1) {
          prefix1 <- prefix %||% idents[i]
        } else {
          prefix1 <- paste0(prefix, idents[i])
        }
        if (method == 1) {
          prefix2 <- paste0(prefix1, ".D")
        } else if (method == 2) {
          prefix2 <- paste0(prefix1, ".D2")
        } else if (method == 3) {
          prefix2 <- paste0(prefix1, ".L")
        }

        tab[[prefix2]] <- e[rownames(object)]
        tab[[paste0(prefix1, ".r")]] <- r[rownames(object)]
        tab[[paste0(prefix1, ".pval")]] <- pval[rownames(object)]
        tab[[paste0(prefix1, ".mean")]] <- mval[rownames(object)]
        tab[[paste0(prefix1, ".var")]] <- vval[rownames(object)]
        tab[[paste0(prefix1, ".padj")]] <- p.adjust(pval[rownames(object)], method = "BH")
        rm(ta)
      }

      if (length(x = messages) > 0) {
        warning("The following tests were not performed: ", call. = FALSE, immediate. = TRUE)
        for (i in 1:length(x = messages)) {
          if (!is.null(x = messages[[i]])) {
            warning("When testing ", idents[i], " : ", messages[[i]], call. = FALSE, immediate. = TRUE)
          }
        }
      }
    }
    
  } else {
    if (is.null(cells)) {
      if (weight.matrix.name %ni% names(object)) {
        stop("No weight matrix found. Perform RunAutoCorr() first.")
      }
      if (verbose) {
        message("Use predefined weight matrix \"", weight.matrix.name, "\"", ".")
      }
      W <- object[[weight.matrix.name]]
      ta <- .Call("D_test", x, y, W, method, perm, threads, idx, bidx, cs, scale.factor, mode, scale, TRUE, seed, debug)
    } else {
      if (verbose) {
        message("Construct SNN graph for cells with \"", reduction, "\"", ".")
      }
      cells <- intersect(cells, colnames(object))
      data.use <- Embeddings(object[[reduction]])
      data.use <- data.use[cells, dims]
      ng <- FindNeighbors(object = data.use,
                          k.param = k.param,
                          compute.SNN = TRUE,
                          prune.SNN = prune.SNN,
                          nn.method = nn.method,
                          annoy.metric = annoy.metric,
                          nn.eps = 0,
                          l2.norm = FALSE, cache.index = FALSE, verbose = FALSE)
      snn <- ng[['snn']]
      W <- GetWeights(snn = snn, prune.SNN = prune.SNN)
      ta <- .Call("D_test", x[,cells], y[,cells], W[cells, cells], method, perm, threads, idx, bidx, cs[cells], scale.factor, mode, scale, TRUE, seed, debug)
    }
    
    if (length(ta) == 1) stop(ta[[1]])
    
    r <- ta[[1]]
    e <- ta[[2]]
    tval <- ta[[3]]
    mval <- ta[[4]]
    vval <- ta[[5]]
    
    names(r) <- features
    names(e) <- features
    names(mval) <- features
    names(vval) <- features
    
    pval <- pt(tval, df = perm - 1, lower.tail = FALSE)
    names(pval) <- features
    prefix <- prefix %||% bind.name
    if (method == 1) {
      prefix1 <- paste0(prefix, ".D")
    } else if (method == 2) {
      prefix1 <- paste0(prefix, ".D2")
    } else if (method == 3) {
      prefix1 <- paste0(prefix, ".L")
    }
    tab[[prefix1]] <- e[rownames(object)]
    tab[[paste0(prefix, ".r")]] <- r[rownames(object)]
    tab[[paste0(prefix, ".pval")]] <- pval[rownames(object)]
    tab[[paste0(prefix, ".mean")]] <- mval[rownames(object)]
    tab[[paste0(prefix, ".var")]] <- vval[rownames(object)]
    tab[[paste0(prefix, ".padj")]] <- p.adjust(pval[rownames(object)], method = "BH")
    rm(ta)
  }
  
  gc()
  object0[[colnames(tab)]] <- tab
  object[[assay]] <- object0
  features <- head(features)
  object <- LogSeuratCommand(object)
  
  tt <- Sys.time()-tt
  if (isTRUE(verbose)) {
    message("Runtime : ",format(tt), ".");
  }
  object
}

cor_dist <- function(x = NULL, y = NULL, W = NULL, perm = 1000, thread = 1)
{
  ta <- .Call("D_distribution_test", x, y, W, perm, thread)
  ta
}

#' @export
SDTdemo <- function(object = NULL, bind.name = NULL, bind.assay = NULL, assay = NULL, mode = c(1,2,3), perm = 100, feature = NULL) {
  
  if (is.null(object)) {
    stop("No object.")
  }

  if (is.null(feature)) {
    stop("No feature.")
  }

  if (is.null(bind.name)) {
    stop("bind.name is not set.")
  }
  assay <- assay %||% DefaultAssay(object)
  old.assay <- DefaultAssay(object)

  DefaultAssay(object) <- assay
  feature <- intersect(rownames(object), feature)

  if (length(feature) == 0) {
    stop("No feature found.")
  }

  df <- object[[assay]][[]]

  if (!(bind.name %in% colnames(df))) {
    stop("No bind.name found.")
  }

  bind.feature <- df[feature, bind.name]

  if (is.na(bind.feature)) {
    stop("bind.feature is NA.")
  }

  x <- GetAssayData(object, layer = "counts")
  cs <- colSums(x)
  
  d1 <- x[feature,]

  d1 <- as.matrix(d1)
  DefaultAssay(object) <- bind.assay

  bind.feature <- intersect(bind.feature, rownames(object))
  if (length(bind.feature) == 0) {
    stop("No bind.feature found.")
  }

  d2 <- GetAssayData(object, layer="counts")[bind.feature,]
  d2 <- as.matrix(d2)
  if (mode ==  2) {
    d2 <- d2 - d1
  }
  if (mode == 3) {
    d2 <- d1 + d2
  }
  
  message("Orginal cor is ", cor(d1[,1], d2[,1]))

  d1[,1] <- log(d1[,1]*1e4/cs+1)
  d2[,1] <- log(d2[,1]*1e4/cs+1)
  
  message("Cor after normlise is ", cor(d1[,1], d2[,1]))
  message("Mean a ", mean(d1[,1]), " mean b ", mean(d2[,1]))
  
  W <- object[['WeightMatrix']]
  W <- as(W, "CsparseMatrix")

  s1 <- (d1[,1] %*% W)[1,]
  s2 <- (d2[,1] %*% W)[1,]
  
  message("Cor after smooth is ", cor(s1, s2))
  message("Mean smooth a ", mean(s1), " mean smooth b ", mean(s2))
  d1 <- d1[,1]
  sm <- mean(d1)
  
  Lx <- sum((s1-sm)^2)/sum((d1-sm)^2)
  
  D <- sqrt(Lx)*(1-cor(s1,s2))

  mn <- lapply(1:perm, function(i) {
    d11 <- sample(d1)
    s11 <- (d11 %*% W)[1,]
    Lx1 <- sum((s11-sm)^2)/sum((d11-sm)^2)
    sqrt(Lx1)*(1-cor(s11,s2))    
  })

  mn <- unlist(mn)
  hist(mn)
  m <- mean(mn)
  var <- sqrt(sum((mn - m)^2)/perm)
  t <- (D-m)/var
  
  p <- pt(t, df = perm-1, lower.tail = FALSE)
  message("Lx is ", Lx, ", D score is ", D)
  message("Mean is ", m, ", var is ", var)
  message("t value is ", t, ";\np value is ", p)

  DefaultAssay(object) <- old.assay
}

