DScore <- function(x = NULL, y = NULL, W = NULL)
{
  d <- .Call("D_score_lite", x, y, W)
  d
}

#
#' @importFrom methods is
#
IdentToCells <- function(
  object,
  ident,
  cellnames.use
) {
  #
  if (is.null(x = ident)) {
    stop("Please provide ident")
  } else if ((length(x = ident) == 1 && ident[1] == 'clustertree') || is(object = ident, class2 = 'phylo')) {
    tree <- if (is(object = ident, class2 = 'phylo')) {
      ident
    } else {
      Tool(object = object, slot = 'BuildClusterTree')
    }
    if (is.null(x = tree)) {
      stop("Please run 'BuildClusterTree' or pass an object of class 'phylo' as 'ident'")
    }
    ident <- tree$tip.label[GetLeftDescendants(tree = tree, node = ident)]
  }
  if (length(x = as.vector(x = ident)) > 1 &&
        any(as.character(x = ident) %in% cellnames.use)) {
    bad.cells <- cellnames.use[which(x = !as.character(x = ident) %in% cellnames.use)]
    if (length(x = bad.cells) > 0) {
      stop(paste0("The following cell names provided to ident are not present in the object: ", paste(bad.cells, collapse = ", ")))
    }
  } else {
    ident <- WhichCells(object = object, idents = ident)
  }
  return(ident)
}


#' @title RunBlockCorr
#' @description Run spatial dissimilarity test for features and their binding features in parallel.
#' @param object Seurat object
#' @param bind.name The title of binding features in the meta table is important, as most users begin Yano to perform alternative splicing analysis. By default, the `bind.name` is set to "gene_name".
#' @param features Vector of features to calculate. Default is AutoCorrFeatures(object).
#' @param assay Work assay.
#' @param min.cells Features detected in few than minimal number of cells will be skipped. Default is 10.
#' @param bind.assay Name of binding assay. If the binding assay is not set, raw counts of features from the same block will be aggregated first, followed by normalization.
#' @param bind.features List of bind features. If set, bind features will be subset with this list.
#' @param min.cells.bind Binding features detected in few than minimal number of cells will be skipped. Default is 10.
#' @param prefix Prefix name for output scores and values. Default is same with bind.name.
#' @param subset Rules for subsetting meta table before selecting features to perform test.
#' @param scale.factor The scale factor used to normalize counts is set to a default of 1e4. The raw counts from "counts" layer are further normalized by sample size and scale factor for the spatial dissimilarity test.
#' @param mode Test mode. Mode 1: Compares X (test feature) vs Y (binding feature). In this mode and bind.assay is set, normlised counts from layer 'data' will be used for comparing.  If bind.assay is none, will use raw counts from layer 'counts'. Mode 2: Compares X vs (Y - X). Mode 3: Compares X vs (Y + X). For mode 2 and 3, only support to use raw counts from layer 'counts'.
#' @param method Method to use. Support D, D2 and Lee. \eqn{D = sqrt(L_x)(1-r_xy)}. \eqn{D2 = sqrt(L_y)(1-r_xy)}. Lee for Lee's Score. In default use D method, see the manual for details.
#' @param library.size Library size for each cell, used for normalise counts. If not set, use colSum(counts) instead.
## @param scale Scale expression of the test feature and binding feature when perfroming test.
#' @param wm.name Weight matrix name, this matrix (graph) generated by \code{\link{RunAutoCorr}}.
#' @param cells Calculate scores for predefined cells. Will reconstruct the SNN graph and weight matrix for these cells with 'reduction' space (usually be pca or harmony). Only weight matrix that calculated by SNN is supported if cells/idents/node is defined.
#' @param idents Calculate scores for these cell groups. The idents should be a vector of group names in Idnets(object).
#' @param node A node to find markers for and all its children; requires \code{\link{BuildClusterTree}} to have been run previously. Only can be used if test all groups.
#' @param perm Permutations for evaluating mean and sd of D/L scores. Default is 100.
#' @param seed Seed for generate random number. Default is 999.
#' @param threads Threads. If set to 0 (default), will auto check the CPU cores and set threads = number of CPU cores -1.
#' @param versbose Print log message. Default is TRUE.
#' @param debug Print debug message. Will auto set thread to 1. Default is FALSE.
#' @param reduction Dimension reduction name for constructing SNN graph and weight matrix. Default is 'pca'. This and following parameters only actived when cells is set, because need to recalculate the SNN graph for the defined cells. 
#' @param dims Dimensions of reduction used to construct SNN graph.
#' @param k.param Defines k for the k-nearest neighbor algorithm.
#' @param prune.SNN Sets the cutoff for acceptable Jaccard index when computing the neighborhood overlap for the SNN construction. Any edges with values less than or equal to this will be set to 0 and removed from the SNN graph. Essentially sets the stringency of pruning (0 --- no pruning, 1 --- prune everything). Default is 1/50.
#' @param nn.method Method for nearest neighbor finding. Options include: rann, annoy(default).
#' @param annoy.metric Distance metric for annoy. Options include: euclidean (default), cosine, manhattan, and hamming
#' @param n.trees More trees gives higher precision when using annoy approximate nearest neighbor search. Default is 50.
#' @param nn.eps Error bound when performing nearest neighbor seach using RANN; default of 0.0 implies exact nearest neighbor search
#' @importFrom Matrix sparseMatrix
#' @export
RunBlockCorr <- function(object = NULL,
                         bind.name = "gene_name",
                         features = NULL,
                         assay = NULL,
                         min.cells = 10,
                         bind.assay = NULL,
                         bind.features = NULL,
                         min.cells.bind = 10,
                         prefix = NULL,
                         subset = NULL,
                         min.features.per.block = 1,
                         scale.factor = 1e4,
                         mode = c(1,2,3),
                         method = c("D", "D2", "Lee"),
                         library.size = NULL,                         
                         wm.name = NULL,
                         perm=100,
                         seed=999,
                         threads = 0,
                         verbose = TRUE,
                         debug = FALSE,
                         cells = NULL,
                         idents = NULL,
                         node = NULL,
                         reduction = "pca",
                         dims = 1:20,
                         k.param = 20,
                         prune.SNN = 1/50,
                         n.trees = 50,
                         nn.eps = 0,
                         nn.method = "annoy",
                         annoy.metric = "euclidean"
                         )
{
  method <- match.arg(method)
  mode <- mode[1L]
  tt <- Sys.time()
  
  assay <- assay %||% DefaultAssay(object)
  if (isTRUE(verbose)) {
    message("Working on assay ", assay, ".")
  }

  if (!is.null(bind.assay)) {
    if (bind.assay %ni% names(object)) {
      stop("No bind.assay is found. Make sure you specify the correct assay name.")
    } else {
      if (isTRUE(verbose)) {
        message("Working on binding assay ", bind.assay, ".")
      }
    }
  }
  
  features <- features %||% AutoCorrFeatures(object)
  features <- intersect(features, rownames(object))

  if (isTRUE(verbose)) {
    message("Processing ", length(features), " features.")
  }
  threads <- getCores(threads)
  
  object0 <- object[[assay]]
  tab <- object0[[]]

  if (bind.name %ni% colnames(tab)) {
    stop("No bind.name found in the feature table of assay ", assay, ". Run ParseExonName or ParseVarName first.")
  }

  # skip unannotated records
  tab <- tab[tab[[bind.name]] != "." & !is.na(tab[[bind.name]]),] 
  
  if (!is.null(subset)) {
    tab <- base::subset(tab, subset = subset)
  }
  
  blocks <- names(which(table(tab[[bind.name]]) >= min.features.per.block))

  bind.features <- bind.features %||% blocks
  blocks <- intersect(bind.features, blocks)
  features <- intersect(features, rownames(tab))

  if (length(features) == 0) {
    stop("No features found.")
  }
  
  tab0 <- tab[features,]
  blocks <- intersect(unique(tab0[[bind.name]]), blocks)

  if (isTRUE(verbose)) {
    message("Processing ", length(blocks), " blocks.")
  }
  tab <- subset(tab, tab[[bind.name]] %in% blocks)
  # features <- intersect(features, rownames(tab))

  x <- GetAssayData1(object, assay = assay, layer = "counts")  
  cs <- library.size %||% colSums(x)

  rs <- Matrix::rowSums(x>0)
  idx <- which(rs >= min.cells)
  features1 <- rownames(object)[idx]
  features <- intersect(features, features1)

  bind.assay <- bind.assay %||% "tmp.assay"
  cells0 <- cells %||% colnames(object)
  cells0 <- intersect(cells0, colnames(object))

  norm <- TRUE
  if (bind.assay %ni% names(object)) {

    if (min.features.per.block == 1) {
      if (isTRUE(verbose)) {
        message("No bind.assay specified, update min.features.per.block to 2.")
      }
      min.features.per.block <- 2
    }

    blocks <- names(which(table(tab[[bind.name]]) >= min.features.per.block))
    tab <- subset(tab, tab[[bind.name]] %in% blocks)
    features <- intersect(features, rownames(tab))

    if (isTRUE(verbose)) {
      message("Use \"counts\" layer for test features.")
      message("Aggregate counts for binding features.")
    }
    x0 <- x[rownames(tab), cells0]
    x0 <- as(x0, "TsparseMatrix")
    
    # Aggregate features in the same block
    y <- sparseMatrix(i = match(tab[[bind.name]][x0@i+1], blocks),
                      j = x0@j+1,
                      x = x0@x, dims=c(length(blocks), length(cells0)))

    rm(x0)
    rownames(y) <- blocks
    colnames(y) <- colnames(x)
  } else {
    blocks <- unique(tab[[bind.name]])
    if (isTRUE(verbose)) {
      message("Retrieve binding data from assay ", bind.assay, ".")
    }
    old.assay <- DefaultAssay(object)
    DefaultAssay(object) <- bind.assay
    blocks <- intersect(blocks, rownames(object))

    y <- GetAssayData1(object, assay = bind.assay, slot = "counts")

    rs <- Matrix::rowSums(y>0)
    idx <- which(rs >= min.cells.bind)
    blocks1 <- rownames(object)[idx]
    blocks <- intersect(blocks, blocks1)

    tab <- subset(tab, tab[[bind.name]] %in% blocks)
    
    DefaultAssay(object) <- old.assay

    if (mode == 1) {
      if (isTRUE(verbose)) {
        message("Use \"data\" layer for test features and binding features.")
      }
      x <- GetAssayData1(object, assay = assay, slot = "data")
      y <- GetAssayData1(object, assay = bind.assay, slot = "data")
      norm <- FALSE
    } else {
      if (isTRUE(verbose)) {
        message("Use \"data\" layer for test features and binding features.")
      }
    }
  }

  features <- intersect(features, rownames(tab))
  tab <- tab[features,]
  bidx <- match(tab[[bind.name]],rownames(y))
  idx <- match(features, rownames(x))
  if (isTRUE(verbose)) {
    message("Using ", threads, " threads.")
  }
  gc()

  if (isTRUE(verbose)) {
    message("Using method \"", method, "\" with mode ", mode, ".")
  }
  method <- switch(method, "D" = 1, "D2" = 2, "L" == 3)
  scale <- FALSE
  tab <- object0[[]]
  
  if (length(idents) > 0 || !is.null(node)) {
    if (verbose) {
      message("Construct SNN graph for cells with \"", reduction, "\"", ".")
    }
    if (!is.null(node)) {
      ## this part copied from Seurat::FindAllMarkers, credited to origial authoers
      if (!PackageCheck('ape', error = FALSE)) {
        stop("Cluster tree functionality requires 'ape', please install with 'install.packages('ape')'")
      }
      tree <- Tool(object = object, slot = 'BuildClusterTree')
      if (is.null(x = tree)) {
        stop("Please run 'BuildClusterTree' before finding markers on nodes")
      }
      descendants <- DFT(tree = tree, node = node, include.children = TRUE)
      all.children <- sort(x = tree$edge[, 2][!tree$edge[, 2] %in% tree$edge[, 1]])
      descendants <- MapVals(
        vec = descendants,
        from = all.children,
        to = tree$tip.label
      )
      drop.children <- setdiff(x = tree$tip.label, y = descendants)
      keep.children <- setdiff(x = tree$tip.label, y = drop.children)
      orig.nodes <- c(
        node,
        as.numeric(x = setdiff(x = descendants, y = keep.children))
      )
      tree <- ape::drop.tip(phy = tree, tip = drop.children)
      new.nodes <- unique(x = tree$edge[, 1, drop = TRUE])
      idents <- (tree$Nnode + 2):max(tree$edge)
    }

    #cellnames.use <- colnames(x = object0)
    cellnames.use <- cells0

    messages <- list()    
    for (i in 1:length(idents)) {
      if (verbose) {
        message("Calculating cluster ", idents[i], ".")
      }

      cells <- IdentToCells(object = object, ident = idents[[i]], cellnames.use = cellnames.use)
      data.use <- Embeddings(object[[reduction]])
      data.use <- data.use[cells, dims]
      ng <- FindNeighbors(object = data.use,
                          k.param = k.param,
                          compute.SNN = TRUE,
                          prune.SNN = prune.SNN,
                          nn.method = nn.method,
                          annoy.metric = annoy.metric,
                          n.trees = n.trees,
                          nn.eps = nn.eps,
                          l2.norm = FALSE, cache.index = FALSE, verbose = FALSE)
      snn <- ng[['snn']]
      W <- GetWeights(snn = snn, prune.SNN = prune.SNN)
      
      ta <- tryCatch(
        expr = {
          .Call("D_test", x[,cells], y[,cells], W[cells,cells], method, perm, threads, idx, bidx, cs[cells], scale.factor, mode, scale, norm, seed, debug)
        },
        error = function(cond){
          return(cond$message)
        }
      )
      
      if (length(ta) == 1) {
        message[[i]] <- ta
      } else {    
        r <- ta[[1]]
        e <- ta[[2]]
        tval <- ta[[3]]
        mval <- ta[[4]]
        vval <- ta[[5]]
        
        names(r) <- features
        names(e) <- features
        names(mval) <- features
        names(vval) <- features
        
        pval <- pt(tval, df = perm - 1, lower.tail = FALSE)
        names(pval) <- features
        if (length(idents) == 1) {
          prefix1 <- prefix %||% idents[i]
        } else {
          prefix1 <- paste0(prefix, idents[i])
        }
        if (method == 1) {
          prefix2 <- paste0(prefix1, ".D")
        } else if (method == 2) {
          prefix2 <- paste0(prefix1, ".D2")
        } else if (method == 3) {
          prefix2 <- paste0(prefix1, ".L")
        }

        tab[[prefix2]] <- e[rownames(object)]
        tab[[paste0(prefix1, ".r")]] <- r[rownames(object)]
        tab[[paste0(prefix1, ".pval")]] <- pval[rownames(object)]
        tab[[paste0(prefix1, ".mean")]] <- mval[rownames(object)]
        tab[[paste0(prefix1, ".var")]] <- vval[rownames(object)]
        tab[[paste0(prefix1, ".padj")]] <- p.adjust(pval[rownames(object)], method = "BH")
        rm(ta)
      }

      if (length(x = messages) > 0) {
        warning("The following tests were not performed: ", call. = FALSE, immediate. = TRUE)
        for (i in 1:length(x = messages)) {
          if (!is.null(x = messages[[i]])) {
            warning("When testing ", idents[i], " : ", messages[[i]], call. = FALSE, immediate. = TRUE)
          }
        }
      }
    }
    
  } else {
    if (is.null(cells)) {
      wm.names <- grep("_wm$", names(object), value = TRUE)
      if (length(wm.names) == 0) {
        stop("No weight matrix found. Perform RunAutoCorr() first.")
      }
      wm.name <- wm.name %||% wm.names[1L]
      if (wm.name %ni% names(object)) {
        stop("No weight matrix found. Perform RunAutoCorr() first.")
      }
      if (verbose) {
        message("Use predefined weight matrix \"", wm.name, "\"", ".")
      }
      W <- object[[wm.name]]
      ta <- .Call("D_test", x, y, W, method, perm, threads, idx, bidx, cs, scale.factor, mode, scale, norm, seed, debug)
    } else {
      if (verbose) {
        message("Construct SNN graph for cells with \"", reduction, "\"", ".")
      }
      cells <- intersect(cells, colnames(object))
      data.use <- Embeddings(object[[reduction]])
      data.use <- data.use[cells, dims]
      ng <- FindNeighbors(object = data.use,
                          k.param = k.param,
                          compute.SNN = TRUE,
                          prune.SNN = prune.SNN,
                          nn.method = nn.method,
                          annoy.metric = annoy.metric,
                          nn.eps = 0,
                          l2.norm = FALSE, cache.index = FALSE, verbose = FALSE)
      snn <- ng[['snn']]
      W <- GetWeights(snn = snn, prune.SNN = prune.SNN)
      ta <- .Call("D_test", x[,cells], y[,cells], W[cells, cells], method, perm, threads, idx, bidx, cs[cells], scale.factor, mode, scale, norm, seed, debug)
    }
    
    if (length(ta) == 1) stop(ta[[1]])
    
    r <- ta[[1]]
    e <- ta[[2]]
    tval <- ta[[3]]
    mval <- ta[[4]]
    vval <- ta[[5]]
    
    names(r) <- features
    names(e) <- features
    names(mval) <- features
    names(vval) <- features
    
    pval <- pt(tval, df = perm - 1, lower.tail = FALSE)
    names(pval) <- features
    prefix <- prefix %||% bind.name
    if (method == 1) {
      prefix1 <- paste0(prefix, ".D")
    } else if (method == 2) {
      prefix1 <- paste0(prefix, ".D2")
    } else if (method == 3) {
      prefix1 <- paste0(prefix, ".L")
    }
    tab[[prefix1]] <- e[rownames(object)]
    tab[[paste0(prefix, ".r")]] <- r[rownames(object)]
    tab[[paste0(prefix, ".pval")]] <- pval[rownames(object)]
    tab[[paste0(prefix, ".mean")]] <- mval[rownames(object)]
    tab[[paste0(prefix, ".var")]] <- vval[rownames(object)]
    tab[[paste0(prefix, ".padj")]] <- p.adjust(pval[rownames(object)], method = "BH")
    rm(ta)
  }
  
  gc()
  object0[[colnames(tab)]] <- tab
  object[[assay]] <- object0
  features <- head(features)
  object <- LogSeuratCommand(object)
  
  tt <- Sys.time()-tt
  if (isTRUE(verbose)) {
    message("Runtime : ",format(tt), ".");
  }
  object
}

cor_dist <- function(x = NULL, y = NULL, W = NULL, perm = 1000, thread = 1)
{
  ta <- .Call("D_distribution_test", x, y, W, perm, thread)
  ta
}

#' @export
SDTdemo <- function(object = NULL, bind.name = NULL, bind.assay = NULL, assay = NULL, mode = c(1,2,3), perm = 100, feature = NULL, library.size = NULL, method = c("D1","D2")) {
  
  if (is.null(object)) {
    stop("No object.")
  }

  if (is.null(feature)) {
    stop("No feature.")
  }

  if (is.null(bind.name)) {
    stop("bind.name is not set.")
  }
  assay <- assay %||% DefaultAssay(object)
  old.assay <- DefaultAssay(object)

  mode <- mode[1L]
  method <- method[1L]
  
  DefaultAssay(object) <- assay
  feature <- intersect(rownames(object), feature)
  feature <- feature[1L]
  
  if (length(feature) == 0) {
    stop("No feature found.")
  }

  df <- object[[assay]][[]]

  if (!(bind.name %in% colnames(df))) {
    stop("No bind.name found.")
  }

  bind.feature <- df[feature, bind.name]

  if (is.na(bind.feature)) {
    stop("bind.feature is NA.")
  }

  if (mode == 1) {
    x <- GetAssayData(object, layer = "data")
    DefaultAssay(object) <- bind.assay
    y <- GetAssayData(object, layer = "data")
  } else {
    x <- GetAssayData(object, layer = "counts")
    DefaultAssay(object) <- bind.assay
    y <- GetAssayData(object, layer = "counts")
    cs <- library.size %||% colSums(x)
  }
  
  d1 <- x[feature,]
  d1 <- as.matrix(d1)

  bind.feature <- intersect(bind.feature, rownames(object))
  if (length(bind.feature) == 0) {
    stop("No bind.feature found.")
  }

  d2 <- y[bind.feature,]
  d2 <- as.matrix(d2)
  if (mode ==  2) {
    d2 <- d2 - d1
  }
  if (mode == 3) {
    d2 <- d1 + d2
  }
  
  message("Orginal cor is ", cor(d1[,1], d2[,1]))

  if (mode != 1) {
    d1[,1] <- log(d1[,1]*1e4/cs+1)
    d2[,1] <- log(d2[,1]*1e4/cs+1)
  }
  
  message("Cor after normlise is ", cor(d1[,1], d2[,1]))
  message("Mean a ", mean(d1[,1]), " mean b ", mean(d2[,1]))
  
  W <- object[['pca_wm']]
  W <- as(W, "CsparseMatrix")

  s1 <- (d1[,1] %*% W)[1,]
  s2 <- (d2[,1] %*% W)[1,]
  
  message("Cor after smooth is ", cor(s1, s2))
  message("Mean smooth a ", mean(s1), " mean smooth b ", mean(s2))
  d1 <- d1[,1]
  d2 <- d2[,1]
  sm <- mean(d1)
  sm2 <- mean(d2)
  Lx <- sum((s1-sm)^2)/sum((d1-sm)^2)
  Ly <- sum((s2-sm2)^2)/sum((d2-sm2)^2)

  D <- sqrt(Lx)*(1-cor(s1,s2))
  D2 <- sqrt(Ly)*(1-cor(s1,s2))
  
  mn <- lapply(1:perm, function(i) {
    d11 <- sample(d1)
    s11 <- (d11 %*% W)[1,]
    Lx1 <- sum((s11-sm)^2)/sum((d11-sm)^2)
    sqrt(Lx1)*(1-cor(s11,s2))    
  })

  mn <- unlist(mn)
  hist(mn)
  m <- mean(mn)
  var <- sqrt(sum((mn - m)^2)/perm)
  t <- (D-m)/var
  
  p <- pt(t, df = perm-1, lower.tail = FALSE)
  message("Lx is ", Lx, ", D score is ", D)
  message("Mean is ", m, ", var is ", var)
  message("t value is ", t, ";\np value is ", p)

  if (method == "D2") {
    message("================== D2 ==========")
    mn <- lapply(1:perm, function(i) {
      d22 <- sample(d2)
      s22 <- (d22 %*% W)[1,]
      Ly1 <- sum((s22-sm2)^2)/sum((d22-sm2)^2)
      sqrt(Ly1)*(1-cor(s1,s22))    
    })

    mn <- unlist(mn)
    hist(mn)
    m <- mean(mn)
    var <- sqrt(sum((mn - m)^2)/perm)
    t <- (D2-m)/var
  
    p <- pt(t, df = perm-1, lower.tail = FALSE)
    message("Ly is ", Ly, ", D2 score is ", D2)
    message("Mean is ", m, ", var is ", var)
    message("t value is ", t, ";\np value of D2 is ", p)
  }
  DefaultAssay(object) <- old.assay
}

